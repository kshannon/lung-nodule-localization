{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To test: \n",
    "1. Create a folder ../data/luna16/\n",
    "2. Create a folder ../data/luna16/subset2\n",
    "    -Under this folder copy one scan for testing (script will process all the scan at this location) \n",
    "      1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016233746780170740405.mhd & raw file \n",
    "      (Google drive https://drive.google.com/drive/u/1/folders/13wmubTgm-7sh3MxPGxqmVZuoqi0G3ufW\n",
    "3. Create a folder ../data/luna16/hdf5\n",
    "    -Under this copy UNET_weights_H5.h5 (download from google drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "import os, glob \n",
    "import os, os.path\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from ipywidgets import interact\n",
    "import json\n",
    "import pickle\n",
    "from UNET_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Prediction on HOLDOUT subset',add_help=True)\n",
    "# parser.add_argument(\"--holdout\", type=int, default=0, help=\"HOLDOUT subset for predictions\")\n",
    "# args = parser.parse_args()\n",
    "# HOLDOUT = args.holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOLDOUT = 5\n",
    "HO_dir = 'HO{}/'.format(HOLDOUT)\n",
    "data_dir = '../data/luna16/'\n",
    "model_wghts = 'hdf5/UNET_weights_H{}.h5'.format(HOLDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PADDED_SIZE = (448, 448, 368)\n",
    "SLICES = 8\n",
    "TILE_SIZE = (448,448,SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_create_loadWghts(img_size=TILE_SIZE):\n",
    "    input_shape = tuple(list(img_size) + [1])\n",
    "    model = create_UNET3D(input_shape, use_upsampling=True)\n",
    "\n",
    "    model.load_weights(data_dir + model_wghts)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'PredictionMask': dice_coef_loss, \\\n",
    "                        'PredictionClass': 'binary_crossentropy'}, \\\n",
    "                  loss_weights={'PredictionMask': 0.8, 'PredictionClass': 0.2},\n",
    "                  metrics={'PredictionMask':dice_coef,'PredictionClass': 'accuracy'})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_mask(model, padded_img):\n",
    "    print ()\n",
    "    predicted_mask = np.zeros(PADDED_SIZE)\n",
    "\n",
    "    for i in range( PADDED_SIZE[2]//SLICES ):\n",
    "        tile = padded_img[:, :, (i*SLICES) : SLICES*(i+1)]\n",
    "        tile = tile.reshape(tuple([1] + list (tile.shape) + [1]))\n",
    "        tile_predictions = model.predict(tile, verbose=2)        \n",
    "#         print (\"Processing tile number : {}\".format(i))\n",
    "        \n",
    "        tile_mask = tile_predictions[0].reshape(TILE_SIZE)\n",
    "        predicted_mask[:, :, (i*SLICES) : SLICES*(i+1)] = tile_mask\n",
    "#         if i == 4:\n",
    "#             break;\n",
    "    return predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}\n",
    "size_dict = {}\n",
    "model = model_create_loadWghts(TILE_SIZE) \n",
    "\n",
    "for f in glob.glob(data_dir + 'subset2/' + '*.mhd'):\n",
    "    print (\"\\n Processing scan file: {}\".format(os.path.basename(f)))\n",
    "    seriesuid = os.path.splitext(os.path.basename(f))[0]\n",
    "    \n",
    "    # Step-1\n",
    "    itk_img = sitk.ReadImage(f) \n",
    "    img_np_array = sitk.GetArrayFromImage(itk_img)\n",
    "    original_size = img_np_array.shape\n",
    "    print (\"Original-Size of loaded image : {}\".format(original_size))\n",
    "    \n",
    "    # Step-2 \n",
    "    itk_img_norm = normalize_img(itk_img)\n",
    "    img_np_array_norm = sitk.GetArrayFromImage(itk_img_norm)\n",
    "    normalized_size = img_np_array_norm.shape\n",
    "    \n",
    "    # Step-3 \n",
    "    img = normalize_HU(img_np_array_norm)\n",
    "    img = np.swapaxes(img, 0,2)\n",
    "    print (\"Normalized input image size: {}\".format(img.shape))\n",
    "    \n",
    "    # Step-4   # Step-5\n",
    "    padded_img = np.zeros(PADDED_SIZE)\n",
    "    padded_img[ :img.shape[0], :img.shape[1], :img.shape[2] ] = img\n",
    "    print (\"Padded-image size: {}\".format(padded_img.shape))\n",
    "    \n",
    "    predicted_mask = find_mask(model, padded_img)\n",
    "    predictions_dict[seriesuid] = (img.shape, padded_img, predicted_mask)\n",
    "    size_dict[seriesuid] = img.shape\n",
    "    \n",
    "pickle.dump(predictions_dict, open('entire_predictions_{}.dat'.format(seriesuid), 'wb'))\n",
    "pickle.dump(size_dict, open('entire_size_{}.dat'.format(seriesuid), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11100446958488c96ffe3de21b76846"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def displaySlice(sliceNo):\n",
    "    \n",
    "    plt.figure(figsize=[20,20]);    \n",
    "    plt.subplot(121)\n",
    "    plt.title(\"True Image\")\n",
    "    plt.imshow(padded_img[:, :, sliceNo], cmap='bone');\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(predicted_mask[:, :, sliceNo], cmap='bone');\n",
    "    plt.title('Slice #{}'.format(sliceNo));\n",
    "\n",
    "    plt.show()\n",
    "interact(displaySlice, sliceNo=(1,img.shape[0],1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Following sections for reference & WIP code snippets -AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Multiple tile test....performance hog, so exploiting the GPU for entire slice without compromising predictions \n",
    "##and for better performance  -AL\n",
    "\n",
    "# slices = 16\n",
    "# predicted_img = np.zeros(padded_size)\n",
    "\n",
    "# for i in range(368//slices):\n",
    "#     tile_1 = padded_img[:224, :224, (i*slices) : slices*(i+1)]\n",
    "#     tile_2 = padded_img[224:, 224:, (i*slices) : slices*(i+1) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slices = 8\n",
    "# predicted_mask = np.zeros(PADDED_SIZE)\n",
    "\n",
    "# for i in range(24//SLICES):\n",
    "#     tile = padded_img[:, :, (i*SLICES) : SLICES*(i+1)]\n",
    "#     tile = tile.reshape(tuple([1] + list (tile.shape) + [1]))\n",
    "# #     print(tile.shape)\n",
    "\n",
    "#     tile_predictions = model.predict(tile, verbose=2)\n",
    "#     tile_mask = tile_predictions[0].reshape(448, 448, 8)\n",
    "    \n",
    "#     print (tile_mask.shape)\n",
    "#     predicted_mask[:, :, (i*SLICES) : SLICES*(i+1)] = tile_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slices = 8\n",
    "# test_slice = padded_img[:, :, :slices]\n",
    "# print(test_slice.shape)\n",
    "# model = model_create_loadWghts(test_slice.shape) \n",
    "# # slice_predictions = model.predict(test_slice, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (\"Shape of predicted mask or segmented image : {}\".format(predictions_small_img[0].shape))\n",
    "# print (\"Shape of predicted class : {}\".format(predictions_small_img[1].shape))\n",
    "# predictions_small_img[0] [:, 25 : 26, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## AL - TEST : making an image of size 48,48,48 with random 0 or 1\n",
    "# ### Case 2 : As a test created an input image of size (1, 48,48,48,1) \n",
    "# # with random 0 or 1; this works fine and able to create predictions successfully\n",
    "# t2 =  np.random.choice(2,(48,48,48))\n",
    "# t2 = t2.reshape(tuple([1] + list (t2.shape) + [1]))\n",
    "\n",
    "# print (\"Shape of test input image : {}\".format(t2.shape))\n",
    "# predictions = model.predict(t2, verbose=2)\n",
    "\n",
    "# print (\"Shape of predicted mask or segmented image : {}\".format(predictions[0].shape))\n",
    "# print (\"Shape of predicted class : {}\".format(predictions[1].shape))\n",
    "# # predictions[0] [:, 25 : 26, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
