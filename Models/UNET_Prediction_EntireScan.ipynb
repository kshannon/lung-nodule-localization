{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To test: \n",
    "1. Create a folder ../data/luna16/\n",
    "2. Create a folder ../data/luna16/subset2\n",
    "    -Under this folder copy one scan for testing (script will process all the scan at this location) \n",
    "      1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016233746780170740405.mhd & raw file \n",
    "      (Google drive https://drive.google.com/drive/u/1/folders/13wmubTgm-7sh3MxPGxqmVZuoqi0G3ufW\n",
    "3. Create a folder ../data/luna16/hdf5\n",
    "    -Under this copy UNET_weights_H2.h5 (download from google drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda3/envs/tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "import os, glob \n",
    "import os, os.path\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from ipywidgets import interact\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from UNET_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Prediction on HOLDOUT subset',add_help=True)\n",
    "# parser.add_argument(\"--holdout\", type=int, default=0, help=\"HOLDOUT subset for predictions\")\n",
    "# args = parser.parse_args()\n",
    "# HOLDOUT = args.holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOLDOUT = 5\n",
    "HO_dir = 'HO{}/'.format(HOLDOUT)\n",
    "data_dir = '/home/tony/data/luna16/'\n",
    "model_wghts = 'hdf5/UNET_weights_modelB_H{}.h5'.format(HOLDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TILE_HSIZE = 64\n",
    "TILE_WSIZE = 64\n",
    "TILE_DSIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_create_loadWghts_Model_B():\n",
    "   \n",
    "    input_shape=(None, None, None, 1)\n",
    "    model = unet3D_modelB(input_shape, use_upsampling=True)\n",
    "\n",
    "    model.load_weights(data_dir + model_wghts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_create_loadWghts_Model_A():\n",
    "   \n",
    "    input_shape=(None, None, None, 1)\n",
    "    model = create_unet3D_Model_A(input_shape, use_upsampling=True)\n",
    "\n",
    "    model.load_weights(data_dir + model_wghts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_create_loadWghts():\n",
    "    \n",
    "    input_shape=(None, None, None, 1)\n",
    "    model = create_UNET3D(input_shape, use_upsampling=True)\n",
    "\n",
    "    model.load_weights(data_dir + model_wghts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_mask(model, img):\n",
    "    \n",
    "    height, width, depth = img.shape\n",
    "    \n",
    "    # Need to do ceiling to get the right prediction mask size\n",
    "    # This way prediction mask will be a multiple of the tile size.\n",
    "    # So just need to pad whole image to that multiple.\n",
    "    # At the end we crop back to the original image size.\n",
    "    pred_height = int(TILE_HSIZE * np.ceil(1.0*height/TILE_HSIZE))\n",
    "    pred_width = int(TILE_WSIZE * np.ceil(1.0*width/TILE_WSIZE))\n",
    "    pred_depth = int(TILE_DSIZE * np.ceil(1.0*depth/TILE_DSIZE))\n",
    "    \n",
    "    # Prediction mask is now a multiple of the TILE_SIZE.\n",
    "    prediction_mask = np.zeros((pred_height, pred_width, pred_depth, 1))\n",
    "    idxH = 0\n",
    "    \n",
    "    for startH_idx in range(0, height, TILE_HSIZE):\n",
    "        \n",
    "        stopH_idx = startH_idx + TILE_HSIZE\n",
    "        if stopH_idx > height:\n",
    "            stopH_idx = height\n",
    "            \n",
    "        idxW = 0\n",
    "        \n",
    "        for startW_idx in range(0, width, TILE_WSIZE):\n",
    "            \n",
    "            stopW_idx = startW_idx + TILE_WSIZE\n",
    "            if stopW_idx > width:\n",
    "                stopW_idx = width\n",
    "                \n",
    "            idxD = 0\n",
    "               \n",
    "            for startD_idx in range(0, depth, TILE_DSIZE):\n",
    "    \n",
    "                stopD_idx = startD_idx + TILE_DSIZE\n",
    "                if stopD_idx > depth:\n",
    "                    stopD_idx = depth\n",
    "            \n",
    "                snippet = img[startH_idx:stopH_idx, startW_idx:stopW_idx, startD_idx:stopD_idx]\n",
    "                \n",
    "                tile = np.zeros([TILE_HSIZE,TILE_WSIZE,TILE_DSIZE])\n",
    "                \n",
    "                snippet_width = stopW_idx - startW_idx\n",
    "                snippet_height = stopH_idx - startH_idx\n",
    "                snippet_depth = stopD_idx - startD_idx\n",
    "                \n",
    "                tile[:snippet_height,:snippet_width,:snippet_depth] = snippet\n",
    "                \n",
    "                tile = np.expand_dims(tile, 0)\n",
    "                tile = np.expand_dims(tile, -1)\n",
    "\n",
    "                tile_mask = model.predict(tile, verbose=0)\n",
    "                \n",
    "                prediction_mask[idxH:(idxH+TILE_HSIZE), idxW:(idxW+TILE_WSIZE), idxD:(idxD+TILE_DSIZE), :] = tile_mask[0]\n",
    "                \n",
    "                idxD += TILE_DSIZE\n",
    "                \n",
    "            idxW += TILE_WSIZE\n",
    "            \n",
    "        idxH += TILE_HSIZE\n",
    "    \n",
    "    return prediction_mask[:height, :width, :depth, :]  # Truncate to original image size\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D U-Net Segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing scan file: 1.3.6.1.4.1.14519.5.2.1.6279.6001.112740418331256326754121315800.mhd\n",
      "Original-Size of loaded image : (149, 512, 512)\n",
      "Normalized input image size: (400, 400, 372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:49<00:00, 169.32s/files]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Mask sum for entire scan: 2053.513652813245\n",
      "Processing runtime: 0:02:54.015185\n",
      "CPU times: user 2min 54s, sys: 53.3 s, total: 3min 48s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = datetime.now()\n",
    "predictions_dict = {}\n",
    "size_dict = {}\n",
    "model = model_create_loadWghts_Model_B() \n",
    "fileCount = len(glob.glob(data_dir + 'subset5/' + '*.mhd'))\n",
    "                \n",
    "for f in tqdm(glob.glob(data_dir + 'subset5/' + '*.mhd'), total=fileCount, unit=\"files\") :\n",
    "    print (\"\\n Processing scan file: {}\".format(os.path.basename(f)))\n",
    "    seriesuid = os.path.splitext(os.path.basename(f))[0]\n",
    "    # Step-1\n",
    "    itk_img = sitk.ReadImage(f) \n",
    "    img_np_array = sitk.GetArrayFromImage(itk_img)\n",
    "    original_size = img_np_array.shape\n",
    "    print (\"Original-Size of loaded image : {}\".format(original_size))\n",
    "    # Step-2 \n",
    "    itk_img_norm = normalize_img(itk_img)\n",
    "    img_np_array_norm = sitk.GetArrayFromImage(itk_img_norm)\n",
    "    normalized_size = img_np_array_norm.shape\n",
    "    # Step-3 \n",
    "    img = img_np_array_norm.copy()\n",
    "#     img = normalize_HU(img_np_array_norm)\n",
    "    img = np.swapaxes(img, 0,2)   ##needed as SITK swaps axis  \n",
    "    print (\"Normalized input image size: {}\".format(img.shape))\n",
    "    \n",
    "    predicted_mask = find_mask(model, img)\n",
    "    predictions_dict[seriesuid] = (img.shape, img, predicted_mask)\n",
    "    size_dict[seriesuid] = img.shape\n",
    "    \n",
    "\n",
    "print('Predicted Mask sum for entire scan: {}'.format(np.sum(predicted_mask)))\n",
    "pickle.dump(predictions_dict, open('Model_B_noHU_entire_predictions_{}.dat'.format(seriesuid), 'wb'))\n",
    "pickle.dump(size_dict, open('Model_B_noHU_entire_size_{}.dat'.format(seriesuid), 'wb'))    \n",
    "print('Processing runtime: {}'.format(datetime.now() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6818b5412e48b08685d59ce65e46bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def displaySlice(sliceNo):\n",
    "    \n",
    "    plt.figure(figsize=[10,10]);    \n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(np.round(predicted_mask[:, :, sliceNo,0]), cmap='bone');\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Overlay Mask\")\n",
    "    plt.imshow(img[:, :, sliceNo], cmap=\"bone\");\n",
    "    plt.imshow(predicted_mask[:, :, sliceNo,0]>0.01, alpha=0.5, cmap='Reds');\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "interact(displaySlice, sliceNo=(1,img.shape[2],1)); #172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Following sections for reference & WIP code snippets -AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Multiple tile test....performance hog, so exploiting the GPU for entire slice without compromising predictions \n",
    "##and for better performance  -AL\n",
    "\n",
    "# slices = 16\n",
    "# predicted_img = np.zeros(padded_size)\n",
    "\n",
    "# for i in range(368//slices):\n",
    "#     tile_1 = padded_img[:224, :224, (i*slices) : slices*(i+1)]\n",
    "#     tile_2 = padded_img[224:, 224:, (i*slices) : slices*(i+1) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slices = 8\n",
    "# predicted_mask = np.zeros(PADDED_SIZE)\n",
    "\n",
    "# for i in range(24//SLICES):\n",
    "#     tile = padded_img[:, :, (i*SLICES) : SLICES*(i+1)]\n",
    "#     tile = tile.reshape(tuple([1] + list (tile.shape) + [1]))\n",
    "# #     print(tile.shape)\n",
    "\n",
    "#     tile_predictions = model.predict(tile, verbose=2)\n",
    "#     tile_mask = tile_predictions[0].reshape(448, 448, 8)\n",
    "    \n",
    "#     print (tile_mask.shape)\n",
    "#     predicted_mask[:, :, (i*SLICES) : SLICES*(i+1)] = tile_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slices = 8\n",
    "# test_slice = padded_img[:, :, :slices]\n",
    "# print(test_slice.shape)\n",
    "# model = model_create_loadWghts(test_slice.shape) \n",
    "# # slice_predictions = model.predict(test_slice, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (\"Shape of predicted mask or segmented image : {}\".format(predictions_small_img[0].shape))\n",
    "# print (\"Shape of predicted class : {}\".format(predictions_small_img[1].shape))\n",
    "# predictions_small_img[0] [:, 25 : 26, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## AL - TEST : making an image of size 48,48,48 with random 0 or 1\n",
    "# ### Case 2 : As a test created an input image of size (1, 48,48,48,1) \n",
    "# # with random 0 or 1; this works fine and able to create predictions successfully\n",
    "# t2 =  np.random.choice(2,(48,48,48))\n",
    "# t2 = t2.reshape(tuple([1] + list (t2.shape) + [1]))\n",
    "\n",
    "# print (\"Shape of test input image : {}\".format(t2.shape))\n",
    "# predictions = model.predict(t2, verbose=2)\n",
    "\n",
    "# print (\"Shape of predicted mask or segmented image : {}\".format(predictions[0].shape))\n",
    "# print (\"Shape of predicted class : {}\".format(predictions[1].shape))\n",
    "# # predictions[0] [:, 25 : 26, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padded_img[225:232, 225:232, 175]\n",
    "# predicted_mask[225:232, 225:232, 175]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
