{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup for Open CV endeavour, using predictions from file \"for_anil.npz\" (Image & predicted mask)\n",
    "1. Setup : \n",
    "    conda install -c menpo opencv3; \n",
    "    pip install imutils (Note - conda install imutils fails)\n",
    "2. OpenCV version: 3.1.0 used\n",
    "\n",
    "3.  Main concern - predicted mask for size 64 has very low sum np.sum; may I need predicted mask for entire scan in npz format (Tony/Suman has to create prediction in npz format and share the result, which I'll load and use for OpenCV countour detection and finding centriod.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 # import the opencv library\n",
    "import imutils\n",
    "# print(\"Your OpenCV version: {}\".format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aluthra/anaconda2/envs/deeplearning/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/aluthra/anaconda2/envs/deeplearning/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "import os, glob \n",
    "import os, os.path\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from ipywidgets import interact, fixed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/luna16/'\n",
    "npz_prediction_file = 'subset2/for_anil.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in loaded dictionary : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['img1',\n",
       " 'prediction_mask1',\n",
       " 'prediction_featuremaps0',\n",
       " 'img0',\n",
       " 'prediction_featuremaps1',\n",
       " 'prediction_mask0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_dict = np.load(data_dir + npz_prediction_file)\n",
    "print (\"Keys in loaded dictionary : \")\n",
    "npz_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = npz_dict.f.img1.reshape(64,64, 64)\n",
    "predicted_mask1 = npz_dict.f.prediction_mask1.reshape(64,64, 64)\n",
    "featuremaps1 = npz_dict.f.prediction_featuremaps1\n",
    "\n",
    "img0 = npz_dict.f.img0.reshape(64,64, 64)\n",
    "predicted_mask0 = npz_dict.f.prediction_mask0.reshape(64,64, 64)\n",
    "featuremaps0 = npz_dict.f.prediction_featuremaps0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss : \n",
    "1. Concern the Predicted mask sum is very low for image of size 64x64x64 (refer cell below)..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted mask sum (Class1) : 3.1760988235473633\n",
      "Rounded Predicted mask sum (Class1): 0.0\n",
      "\n",
      "Predicted mask sum (Class0): 0.005565871950238943\n",
      "Rounded Predicted mask sum (Class0): 0.0\n"
     ]
    }
   ],
   "source": [
    "rounded_predicted_mask1 = np.round(predicted_mask1)\n",
    "print (\"Predicted mask sum (Class1) : {}\".format(np.sum(predicted_mask1)))\n",
    "print (\"Rounded Predicted mask sum (Class1): {}\".format(np.sum(rounded_predicted_mask1)))\n",
    "\n",
    "rounded_predicted_mask0 = np.round(predicted_mask0)\n",
    "print (\"\\nPredicted mask sum (Class0): {}\".format(np.sum(predicted_mask0)))\n",
    "print (\"Rounded Predicted mask sum (Class0): {}\".format(np.sum(rounded_predicted_mask0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displaySlice(class_type, img, mask, sliceNo):\n",
    "    plt.figure(figsize=[20,20]);    \n",
    "    plt.subplot(121)\n",
    "    plt.title('True Image ({})'.format(class_type))\n",
    "    plt.imshow(img[:, :, sliceNo], cmap='bone');\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.title('Predicted Mask ({})'.format(class_type))\n",
    "    plt.imshow(mask[:, :, sliceNo], cmap='bone');\n",
    "#     plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a12e28c16e341a397c77d84228398c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(displaySlice,class_type=fixed('Class1'),img=fixed(img1), \\\n",
    "         mask=fixed(predicted_mask1), sliceNo=(0,img1.shape[2]-1,1) );\n",
    "# interact(displaySlice,class_type=fixed('Class0'),img=fixed(img0), \\\n",
    "#          mask=fixed(predicted_mask0), sliceNo=(0,img0.shape[2]-1,1) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion (AL/Tony) :\n",
    "1. CV2 usage - Rounded_predicted_mask1 or predicted_mask1 ....? \n",
    "2. Process 3D image in 2D slice's and then find countour in each 2D slice...? \n",
    "3. Convert image from BGR to RGB as OpenCV represents RGB images in reverse order by: \n",
    "    cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "4. Note the np.sum(predicted mask) is very low ~3 (concern to me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AL - should loop thru all the slice and find the slice with most 1's (white marks)\n",
    "#For now using one slice i.e 2D image for CV2 as Slice# 33 has few white marks (refer slider)\n",
    "test_slice = predicted_mask1[:, :, 33]   \n",
    "cv2.imwrite(\"tst.png\", test_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #AL/Tony....?\n",
    "# convert image from BGR to RGB as OpenCV represents RGB images in reverse order\n",
    "# cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image = cv2.imread(\"tst.png\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "\n",
    "thresh_image = cv2.threshold(gray_image, 75, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# gray[25:45, 25:45]\n",
    "# thresh[25:45, 25:45]   # show all zero's  though we expect One's at slice#32 around center\n",
    "# cv2.imshow(\"testWindow\", thresh_image)\n",
    "## cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts = cv2.findContours(thresh_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if imutils.is_cv2() else cnts[1]  #No contours found...?\n",
    "cnts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Above no contour found....?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_THRESH = 9 #nodule of area 3X3 (i.e. 9mm) can be ignored\n",
    "\n",
    "for c in cnts:\n",
    "    if cv2.contourArea(c) > MIN_THRESH:\n",
    "        \n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        area = int(M[\"m00\"])\n",
    "\n",
    "        # draw the contour and center of the shape on the image\n",
    "        cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "        cv2.circle(image, (cX, cY), 7, (255, 255, 255), -1)\n",
    "        cv2.putText(image, \"Nodule-Centriod\", (cX - 20, cY - 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "# show the image\n",
    "# cv2.imshow(\"Image Window\", thresh_image)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result/Discussion on Erosion & Dilation operations\n",
    "1. Perform dilation (to increase white region as we are getting very small sizes)\n",
    "2. Then performing Erosion operation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((7,7), np.uint8)\n",
    "img_dilation = cv2.dilate(image, kernel, iterations=1)\n",
    "img_erosion = cv2.erode(img_dilation, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEICAYAAAB/KknhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIIfUaEEP6JC/w+EG7eYHPxVXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f91f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Dilated-Image\");\n",
    "plt.imshow(img_dilation);  #noticed all the dilated images are black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interact(displaySlice,class_type=fixed('Rounded Mask -Class1'),img=fixed(img1), \\\n",
    "#          mask=fixed(rounded_predicted_mask1), sliceNo=(0,img1.shape[2]-1,1) );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
