{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from keras.models import load_model\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "import os, glob \n",
    "import os, os.path\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from UNET_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Prediction on HOLDOUT subset',add_help=True)\n",
    "# parser.add_argument(\"--holdout\", type=int, default=0, help=\"HOLDOUT subset for predictions\")\n",
    "# args = parser.parse_args()\n",
    "# HOLDOUT = args.holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOLDOUT = 5\n",
    "HO_dir = 'HO{}/'.format(HOLDOUT)\n",
    "data_dir = '../data/luna16/'\n",
    "model_wghts = 'hdf5/UNET_weights_H{}.h5'.format(HOLDOUT)\n",
    "\n",
    "# img_filename = '1.3.6.1.4.1.14519.5.2.1.6279.6001.112767175295249119452142211437.mhd'\n",
    "# model_file = 'hdf5/cnn_3DUNET_64_64_64_HOLDOUT1_20180420_120442.hdf5'\n",
    "# c_objects={'dice_coef_loss': dice_coef_loss,'dice_coef':dice_coef}\n",
    "# model = load_model(data_dir + model_file, custom_objects=c_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size_equal(s1, s2):\n",
    "    return sorted(s1) == sorted(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_create_load(padded_img):\n",
    "    input_shape = padded_img.reshape(tuple(list (padded_img.shape) + [1])).shape\n",
    "    model = create_UNET3D(input_shape)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'PredictionMask': dice_coef_loss, \\\n",
    "                        'PredictionClass': 'binary_crossentropy'}, \\\n",
    "                  loss_weights={'PredictionMask': 0.8, 'PredictionClass': 0.2},\n",
    "                  metrics={'PredictionMask':dice_coef,'PredictionClass': 'accuracy'})\n",
    "\n",
    "    # print(tmp_model.summary())\n",
    "    model.load_weights(data_dir + model_wghts, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing scan file: ../data/luna16/HO5/1.3.6.1.4.1.14519.5.2.1.6279.6001.112767175295249119452142211437.mhd\n",
      "Original-Size of loaded image : (117, 512, 512)\n",
      "Normalized-Size of image : (292, 400, 400)\n",
      "Swapped axis input image : (400, 400, 292)\n",
      "Size of input padded image : (1, 480, 480, 368, 1)\n",
      "\n",
      " Processing scan file: ../data/luna16/HO5/1.3.6.1.4.1.14519.5.2.1.6279.6001.278660284797073139172446973682.mhd\n",
      "Original-Size of loaded image : (117, 512, 512)\n",
      "Normalized-Size of image : (292, 340, 340)\n",
      "Swapped axis input image : (340, 340, 292)\n",
      "Size of input padded image : (1, 480, 480, 368, 1)\n"
     ]
    }
   ],
   "source": [
    "padded_size = (480, 480, 368)\n",
    "predictions_dict = {}\n",
    "size_dict = {}\n",
    "prev_img_size = (0,0,0)\n",
    "\n",
    "for f in glob.glob(data_dir + HO_dir + '*.mhd'):\n",
    "    print (\"\\n Processing scan file: {}\".format(f))\n",
    "    \n",
    "    itk_img = sitk.ReadImage(f) \n",
    "    img_np_array = sitk.GetArrayFromImage(itk_img)\n",
    "    original_size = img_np_array.shape\n",
    "    print (\"Original-Size of loaded image : {}\".format(original_size))\n",
    "    \n",
    "    ## Normalizing the image size ...Need to confirm?  AL\n",
    "    itk_img_norm = normalize_img(itk_img)\n",
    "    img_np_array_norm = sitk.GetArrayFromImage(itk_img_norm)\n",
    "    normalized_size = img_np_array_norm.shape\n",
    "#     print (\"Normalized-Size of image : {}\".format(normalized_size))\n",
    "    \n",
    "    # Normalizing HU of image\n",
    "    img = normalize_HU(img_np_array_norm)\n",
    "    img = np.swapaxes(img, 0,2)\n",
    "    print (\"Swapped axis input image : {}\".format(img.shape))\n",
    "    \n",
    "    padded_img = np.zeros(padded_size)\n",
    "    padded_img[ :img.shape[0], :img.shape[1], :img.shape[2] ] = img\n",
    "    \n",
    "    model = model_create_load(padded_img)      \n",
    "    padded_img = padded_img.reshape(tuple([1] + list (padded_img.shape) + [1]))\n",
    "    print (\"Size of input padded image : {}\".format(padded_img.shape))\n",
    "\n",
    "    #### Owing to large image size requiring heaving processing my m/c hangs\n",
    "    #### For predictions - uncomment the following line on AWS or GPU m/c\n",
    "#     f_predictions = model.predict(padded_img, verbose=1)\n",
    "#     predictions_dict[f] = f_predictions\n",
    "    size_dict[f] = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'../data/luna16/HO5/1.3.6.1.4.1.14519.5.2.1.6279.6001.112767175295249119452142211437.mhd': (400,\n",
       "  400,\n",
       "  292),\n",
       " '../data/luna16/HO5/1.3.6.1.4.1.14519.5.2.1.6279.6001.278660284797073139172446973682.mhd': (340,\n",
       "  340,\n",
       "  292)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with image of size 48,48,48 initialized with random between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_img = np.random.rand(48,48,48)\n",
    "small_img = small_img.reshape(tuple([1] + list (small_img.shape) + [1]))\n",
    "# small_img.shape \n",
    "small_shape = (48, 48, 48, 1)\n",
    "model = create_UNET3D(small_shape)\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'PredictionMask': dice_coef_loss, \\\n",
    "                    'PredictionClass': 'binary_crossentropy'}, \\\n",
    "              loss_weights={'PredictionMask': 0.8, 'PredictionClass': 0.2},\n",
    "              metrics={'PredictionMask':dice_coef,'PredictionClass': 'accuracy'})\n",
    "# print(tmp_model.summary())\n",
    "model.load_weights(data_dir + model_wghts, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 9s 9s/step\n"
     ]
    }
   ],
   "source": [
    "predictions_small_img = model.predict(small_img, verbose=1)\n",
    "result = pd.DataFrame(predictions_small_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (\"Shape of predicted mask or segmented image : {}\".format(predictions_small_img[0].shape))\n",
    "# print (\"Shape of predicted class : {}\".format(predictions_small_img[1].shape))\n",
    "# predictions_small_img[0] [:, 25 : 26, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## AL - TEST : making an image of size 48,48,48 with random 0 or 1\n",
    "# ### Case 2 : As a test created an input image of size (1, 48,48,48,1) \n",
    "# # with random 0 or 1; this works fine and able to create predictions successfully\n",
    "# t2 =  np.random.choice(2,(48,48,48))\n",
    "# t2 = t2.reshape(tuple([1] + list (t2.shape) + [1]))\n",
    "\n",
    "# print (\"Shape of test input image : {}\".format(t2.shape))\n",
    "# predictions = model.predict(t2, verbose=2)\n",
    "\n",
    "# print (\"Shape of predicted mask or segmented image : {}\".format(predictions[0].shape))\n",
    "# print (\"Shape of predicted class : {}\".format(predictions[1].shape))\n",
    "# # predictions[0] [:, 25 : 26, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
