{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to load and test your hdf5 and ensure it was created properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keil/miniconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5_data_loader as loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT11T12KHpath_to_hdf5 = '/Users/keil/datasets/LUNA16/64x64x1-patch.hdf5' # 2D\n",
    "# path_to_hdf5 = '/Users/keil/datasets/LUNA16/64x64x3-patch.hdf5' # 2.5D\n",
    "\n",
    "hdf5_file = h5py.File(path_to_hdf5, 'r') # open in read-only mode\n",
    "\n",
    "data_dataset = 'input'\n",
    "class_dataset = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_hdf5 = '/Users/keil/datasets/LUNA16/64x64x64-patch-annotations.hdf5' # 2D\n",
    "# path_to_hdf5 = '/Users/keil/datasets/LUNA16/64x64x3-patch.hdf5' # 2.5D\n",
    "\n",
    "hdf5_file = h5py.File(path_to_hdf5, 'r') # open in read-only mode\n",
    "\n",
    "data_dataset = 'input'\n",
    "class_dataset = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info and some real data:\n",
      "centroid\n",
      "<HDF5 dataset \"centroid\": shape (128, 3), type \"<f8\">\n",
      "[[ -81.21264213   38.50543905 -161.7782189 ]\n",
      " [ 112.2326686     9.72289057 -197.4920729 ]]\n",
      "diameter\n",
      "<HDF5 dataset \"diameter\": shape (128, 1), type \"<f8\">\n",
      "[[4.51219017]\n",
      " [3.89977046]]\n",
      "input\n",
      "<HDF5 dataset \"input\": shape (128, 262144), type \"<f4\">\n",
      "[[-861. -828. -814. ... -433. -759. -818.]\n",
      " [  58.   43.   57. ...   40.   42.   60.]]\n",
      "output\n",
      "<HDF5 dataset \"output\": shape (128, 1), type \"<i8\">\n",
      "[[1]\n",
      " [1]]\n",
      "subsets\n",
      "<HDF5 dataset \"subsets\": shape (128, 1), type \"<i8\">\n",
      "[[2]\n",
      " [2]]\n",
      "uuid\n",
      "<HDF5 dataset \"uuid\": shape (128, 1), type \"|O\">\n",
      "[[b'1.3.6.1.4.1.14519.5.2.1.6279.6001.217697417596902141600884006982']\n",
      " [b'1.3.6.1.4.1.14519.5.2.1.6279.6001.217697417596902141600884006982']]\n"
     ]
    }
   ],
   "source": [
    "print('Dataset info and some real data:')\n",
    "for name in [key for key in hdf5_file.keys()]:\n",
    "    print(name)\n",
    "    print(hdf5_file[name]) #name + shape + dtype of the dataset (refer back to extract_patch.py)\n",
    "    print(hdf5_file[name][0:2]) #get the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hdf5_file['subsets'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(hdf5_file['subsets'][:] == 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['centroid', 'diameter', 'input', 'output', 'subsets', 'uuid']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key in hdf5_file.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexes for: \n",
    "- subsets: dict{subset : [idxs]}\n",
    "- subsets --> class dict{class : [idxs]}\n",
    "- subsets --> class 0 --> train/notrain: dict{train/notrain(bool): [idxs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loader.HDF5Matrix(path_to_hdf5,data_dataset)\n",
    "test_output = loader.HDF5Matrix(path_to_hdf5,class_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (875, 4096)\n",
      "dtype: float32\n",
      "ndim: 2\n",
      "size: 3584000\n"
     ]
    }
   ],
   "source": [
    "print('shape: {}'.format(test.shape)) #Gets a numpy-style shape tuple giving the dataset dimensions.\n",
    "print('dtype: {}'.format(test.dtype)) #Gets the datatype of the dataset\n",
    "print('ndim: {}'.format(test.ndim)) #Gets the number of dimensions (rank) of the dataset.\n",
    "print('size: {}'.format(test.size)) #returns np.prod(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-892. -840. -789. ...,   28.   31.    4.]\n",
      "4096\n",
      "[  37.   34.   10. ..., -872. -859. -854.]\n",
      "4096\n",
      "[-947. -895. -825. ..., -762. -784. -746.]\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "for key in range(3):\n",
    "    data_row = test.__getitem__(key)\n",
    "    print(data_row)\n",
    "    print(len(data_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-892., -840., -789., ...,   28.,   31.,    4.],\n",
       "       [  37.,   34.,   10., ..., -872., -859., -854.],\n",
       "       [-947., -895., -825., ..., -762., -784., -746.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-892., -840., -789., ...,   28.,   31.,    4.],\n",
       "       [-947., -895., -825., ..., -762., -784., -746.],\n",
       "       [ 241.,  269.,  254., ..., -809., -828., -816.],\n",
       "       [-929., -951., -869., ...,  205.,  468.,  374.],\n",
       "       [ 220.,  240.,  231., ..., -899., -899., -926.]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__([0,2,99,101,600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.__getitem__([0,2,99,101,600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to augment code to pass a list of idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loader.HDF5Matrix(path_to_hdf5,data_dataset,start=0, end=3) #0 n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = test.__getitem__([0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.__getitem__([6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-892., -840., -789., ...,   28.,   31.,    4.],\n",
       "       [  37.,   34.,   10., ..., -872., -859., -854.],\n",
       "       [-947., -895., -825., ..., -762., -784., -746.],\n",
       "       [-762., -887., -904., ...,    1.,   44.,  131.],\n",
       "       [-938., -950., -944., ...,  109.,  100.,  119.],\n",
       "       [-913., -991., -992., ...,  226.,  215.,  211.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-984., -977., -961., ...,  -34.,  -49.,  -60.],\n",
       "       [-878., -898., -948., ...,   88.,   90.,   83.],\n",
       "       [-906., -904., -902., ...,    5.,   27.,   58.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset info and some real data:')\n",
    "for name in [key for key in hdf5_file.keys()]:\n",
    "    print(name)\n",
    "    print(hdf5_file[name]) #name + shape + dtype of the dataset (refer back to extract_patch.py)\n",
    "    print(hdf5_file[name][0:5]) #get the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
