{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2D patches for training\n",
    "\n",
    "Let's run an end-to-end Keras training script with data from our S3 bucket. The data is stored on the S3 bucket in an HDF5 file. This test will give us an idea of the speed and cost of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = !pwd\n",
    "s3bucket_path = root_dir[0] + '/../s3bucket_goofys/' # remote S3 via goofys\n",
    "path_to_hdf5 = s3bucket_path + 'LUNA16/hdf5-files/64x64x1-patch.hdf5'\n",
    "hdf5_file = h5py.File(path_to_hdf5, 'r') # open in read-only mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid hdf5 file in 'read' mode: <HDF5 file \"64x64x1-patch.hdf5\" (mode r)>\n",
      "Size of hdf5 file: 11.851 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid hdf5 file in 'read' mode: \" + str(hdf5_file))\n",
    "file_size = os.path.getsize(path_to_hdf5)\n",
    "print('Size of hdf5 file: {:.3f} GB'.format(file_size/2.0**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 754962 images in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} images in the dataset.\".format(hdf5_file['input'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datasets within the HDF5 file are:\n",
      " [<HDF5 dataset \"centroid\": shape (754962, 3), type \"<f8\">, <HDF5 dataset \"input\": shape (754962, 4096), type \"<f4\">, <HDF5 dataset \"notrain\": shape (754962, 1), type \"<i8\">, <HDF5 dataset \"output\": shape (754962, 1), type \"<i8\">, <HDF5 dataset \"subsets\": shape (754962, 1), type \"<i8\">, <HDF5 dataset \"uuid\": shape (754962, 1), type \"|O\">]\n"
     ]
    }
   ],
   "source": [
    "print(\"The datasets within the HDF5 file are:\\n {}\".format(list(hdf5_file.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_idx = hdf5_file[\"output\"][50:75]\n",
    "type (less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Following line makes m/c crumble......AL\n",
    "tst1 = (hdf5_file['output'][:] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_training = (hdf5_file[\"notrain\"][:,0] == 1)\n",
    "for_testing = (hdf5_file[\"notrain\"][:,0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_idx(hdf5_file, classid = 0):\n",
    "    '''\n",
    "    Get the indices for the class classid and valid for training \n",
    "    '''\n",
    "    # 1. Select indices from class 0 and 1\n",
    "    #idx = np.where(hdf5_file[\"output\"][:,0] == classid)[0]  # Indices for class classid\n",
    "    #idx = np.where(hdf5_file['output'][:] == classid)[0]  #Valid for MNIST hdfs\n",
    "    idx = np.where( (hdf5_file['output'][:,0] == classid) & for_training )[0]  #Valid 2D Patches with No train option\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_exclude_subset_idx(hdf5_file, idx, excluded_subset=0):\n",
    "    '''\n",
    "    Remove indices for the subset excluded_subset\n",
    "    '''   \n",
    "\n",
    "    subsets = hdf5_file[\"subsets\"][:,0]\n",
    "    excluded_idx = np.where(subsets == excluded_subset)[0] # indices\n",
    "    \n",
    "    return np.setdiff1d(idx, excluded_idx)  # Remove the indices of the excluded subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx[0] = get_class_idx(hdf5_file, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx_for_classes(hdf5_file, excluded_subset=0):\n",
    "    '''\n",
    "    Get the indices for each class but don't include indices from excluded subset\n",
    "    '''\n",
    "    \n",
    "    idx = {}\n",
    "    idx[0] = get_class_idx(hdf5_file, 0)\n",
    "    idx[1] = get_class_idx(hdf5_file, 1)\n",
    "#     idx[0] = get_class_idx(hdf5_file, 4)   #used for mist hdfs file\n",
    "#     idx[1] = get_class_idx(hdf5_file, 5)    #used for mist hdfs file\n",
    "    \n",
    "    idx[0] = remove_exclude_subset_idx(hdf5_file, idx[0], excluded_subset)\n",
    "    idx[1] = remove_exclude_subset_idx(hdf5_file, idx[1], excluded_subset)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom HDF5 dataloader\n",
    "\n",
    "This is the first pass at our custom HDF5 data loader.\n",
    "We'll need to add data augmentation and class balancing to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_idx(hdf5_file, idx, batch_size = 20):\n",
    "    '''\n",
    "    Batch size needs to be even.\n",
    "    This is yield a balanced set of random indices for each class. \n",
    "    '''\n",
    "        \n",
    "    idx0 = idx[0]\n",
    "    idx1 = idx[1]\n",
    "    \n",
    "    # 2. Shuffle the two indices\n",
    "    np.random.shuffle(idx0)  # This shuffles in place\n",
    "    np.random.shuffle(idx1)  # This shuffles in place\n",
    "\n",
    "    # 3. Take half of the batch from each class\n",
    "    idx0_shuffle = idx0[0:(batch_size//2)]\n",
    "    idx1_shuffle = idx1[0:(batch_size//2)]\n",
    "\n",
    "    # Need to sort final list in order to slice\n",
    "    return np.sort(np.append(idx0_shuffle, idx1_shuffle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_rotate(img):\n",
    "    '''\n",
    "    Perform a random rotation on the tensor\n",
    "    `img` is the tensor\n",
    "    '''\n",
    "    shape = img.shape\n",
    "    # This will flip along n-1 axes. (If we flipped all n axes then we'd get the same result every time)\n",
    "    ax = np.random.choice(len(shape)-1,2, replace=False) # Choose randomly which axes to flip\n",
    "    return np.flip(img.swapaxes(ax[0], ax[1]), ax[0]) # Random +90 or -90 rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_flip(img):\n",
    "    '''\n",
    "    Performs a random flip on the tensor.\n",
    "    If the tensor is C x H x W x D this will perform flips on two of the C, H, D dimensions\n",
    "    If the tensor is C x H x W this will perform flip on either the H or the W dimension.\n",
    "    `img` is the tensor\n",
    "    '''\n",
    "    shape = img.shape\n",
    "    # This will flip along n-1 axes. (If we flipped all n axes then we'd get the same result every time)\n",
    "    ax = np.random.choice(len(shape)-1,len(shape)-2, replace=False) + 1 # Choose randomly which axes to flip\n",
    "    for i in ax:\n",
    "        img = np.flip(img, i) # Randomly flip along all but one axis\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_data(imgs):\n",
    "    ''' \n",
    "    Performs random flips, rotations, and other operations on the image tensors.\n",
    "    '''\n",
    "    \n",
    "    imgs_length = imgs.shape[0]\n",
    "    \n",
    "    for idx in range(imgs_length):\n",
    "        img = imgs[idx, :]\n",
    "        \n",
    "        if (np.random.rand() > 0.5):\n",
    "            \n",
    "            if (np.random.rand() > 0.5):\n",
    "                img = img_rotate(img)\n",
    "\n",
    "            if (np.random.rand() > 0.5):\n",
    "                img = img_flip(img)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if (np.random.rand() > 0.5):\n",
    "                img = img_flip(img)\n",
    "                \n",
    "            if (np.random.rand() > 0.5):\n",
    "                img = img_rotate(img)\n",
    "\n",
    "        imgs[idx,:] = img\n",
    "        \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(hdf5_file, batch_size=50, exclude_subset=0):\n",
    "    \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "    \"\"\" Randomly select batch_size rows from the hdf5 file dataset \"\"\"\n",
    "    \n",
    "#    input_shape = tuple([batch_size] + list(hdf5_file['input'].attrs['lshape']) + [1])\n",
    "    input_shape = tuple(list(hdf5_file[\"input\"].attrs[\"lshape\"]) [:-1])  # Removing last dim - discuss Tony on lshape\n",
    "    idx_master = get_idx_for_classes(hdf5_file, exclude_subset) \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        random_idx = get_random_idx(hdf5_file, idx_master, batch_size)\n",
    "        imgs = hdf5_file[\"input\"][random_idx,:]\n",
    "        imgs = imgs.reshape(input_shape)\n",
    "        ## Need to augment \n",
    "        imgs = augment_data(imgs)\n",
    "        \n",
    "        #classes = hdf5_file[\"output\"][random_idx,0]\n",
    "#        classes = hdf5_file[\"output\"][list(random_idx)] - 4  #NOTE:Change me back,Anil\n",
    "        classes = hdf5_file[\"output\"][list(random_idx, 0)] \n",
    "        \n",
    "        yield imgs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_shape = tuple(list(hdf5_file[\"input\"].attrs[\"lshape\"]) + [1])  # Get the original shape of the tensor\n",
    "input_shape = tuple(list(hdf5_file[\"input\"].attrs[\"lshape\"]) [:-1])  # Removing last dim\n",
    "batch_size = 20   # Batch size to use\n",
    "print (input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imgs, classes = generate_data(hdf5_file, batch_size=batch_size, exclude_subset=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imgs = hdf5_file[\"inputs\"][random_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imgs = imgs.reshape(10,64,64,64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,391,873\n",
      "Trainable params: 7,391,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tb_log = keras.callbacks.TensorBoard(log_dir='./tb_2D_logs', histogram_freq=0, batch_size=batch_size, \n",
    "                            write_graph=True, \n",
    "                            write_grads=True, write_images=True, \n",
    "                            embeddings_freq=0, embeddings_layer_names=None, \n",
    "                            embeddings_metadata=None)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with fit_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generate_data(hdf5_file, batch_size, exclude_subset=2),\n",
    "                    steps_per_epoch=10, epochs=3)\n",
    "# history = model.fit_generator(generate_data(hdf5_file, batch_size, exclude_subset=2),\n",
    "#                     steps_per_epoch=10, epochs=3, callbacks=[tb_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
